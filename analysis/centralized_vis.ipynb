{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77bfa2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lmfit import Model\n",
    "import glob\n",
    "import re\n",
    "from bokeh.plotting import figure, output_file, save\n",
    "from bokeh.models import Select, ColumnDataSource, Div, CustomJS\n",
    "from bokeh.layouts import column, row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e5b9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 183 curves to 'analysis/noise_fit_parameters.csv'\n",
      "                              curve_id     category      metric       method  \\\n",
      "0    SC_Protein MI_Rand. Proj._size100  Single-cell  Protein MI  Rand. Proj.   \n",
      "1            SC_Protein MI_PCA_size100  Single-cell  Protein MI          PCA   \n",
      "2           SC_Protein MI_SCVI_size100  Single-cell  Protein MI         SCVI   \n",
      "3     SC_Protein MI_Geneformer_size100  Single-cell  Protein MI   Geneformer   \n",
      "4    SC_Protein MI_Rand. Proj._size215  Single-cell  Protein MI  Rand. Proj.   \n",
      "5            SC_Protein MI_PCA_size215  Single-cell  Protein MI          PCA   \n",
      "6           SC_Protein MI_SCVI_size215  Single-cell  Protein MI         SCVI   \n",
      "7     SC_Protein MI_Geneformer_size215  Single-cell  Protein MI   Geneformer   \n",
      "8    SC_Protein MI_Rand. Proj._size464  Single-cell  Protein MI  Rand. Proj.   \n",
      "9            SC_Protein MI_PCA_size464  Single-cell  Protein MI          PCA   \n",
      "10          SC_Protein MI_SCVI_size464  Single-cell  Protein MI         SCVI   \n",
      "11    SC_Protein MI_Geneformer_size464  Single-cell  Protein MI   Geneformer   \n",
      "12  SC_Protein MI_Rand. Proj._size1000  Single-cell  Protein MI  Rand. Proj.   \n",
      "13          SC_Protein MI_PCA_size1000  Single-cell  Protein MI          PCA   \n",
      "14         SC_Protein MI_SCVI_size1000  Single-cell  Protein MI         SCVI   \n",
      "15   SC_Protein MI_Geneformer_size1000  Single-cell  Protein MI   Geneformer   \n",
      "16  SC_Protein MI_Rand. Proj._size2154  Single-cell  Protein MI  Rand. Proj.   \n",
      "17          SC_Protein MI_PCA_size2154  Single-cell  Protein MI          PCA   \n",
      "18         SC_Protein MI_SCVI_size2154  Single-cell  Protein MI         SCVI   \n",
      "19   SC_Protein MI_Geneformer_size2154  Single-cell  Protein MI   Geneformer   \n",
      "\n",
      "          size        u_bar     I_max    u_bar_err  I_max_err  r_squared  \n",
      "0    100 cells  4874.076236  3.147374   557.409760   0.086920   0.995624  \n",
      "1    100 cells  3435.419321  3.736421   562.755118   0.124877   0.990209  \n",
      "2    100 cells  1029.380851  3.090557   171.189563   0.135988   0.972773  \n",
      "3    100 cells    62.976229  1.912528    12.755560   0.189198   0.866143  \n",
      "4    215 cells  4907.471006  3.158055   423.043628   0.065838   0.997020  \n",
      "5    215 cells  3549.022448  3.782690   543.044954   0.118234   0.990105  \n",
      "6    215 cells   766.450292  2.977734   118.582556   0.127768   0.977290  \n",
      "7    215 cells   134.925581  2.260954    53.419810   0.354608   0.693750  \n",
      "8    464 cells  4411.983069  3.098674   382.363157   0.066781   0.996898  \n",
      "9    464 cells  4626.588672  3.981929   640.713293   0.104948   0.993447  \n",
      "10   464 cells   616.697768  3.011823   117.110915   0.158380   0.956107  \n",
      "11   464 cells   152.272714  2.428835    47.968970   0.279744   0.803930  \n",
      "12  1000 cells  4826.307657  3.150997   451.885857   0.071917   0.996872  \n",
      "13  1000 cells  6872.662550  4.281749  1136.631496   0.123675   0.993638  \n",
      "14  1000 cells   813.668170  3.269612   165.013276   0.168697   0.961218  \n",
      "15  1000 cells   259.352369  2.805489    83.904030   0.280358   0.845877  \n",
      "16  2154 cells  5114.776159  3.183275   516.519696   0.076787   0.996856  \n",
      "17  2154 cells  6066.946318  4.173417  1340.850573   0.165669   0.987703  \n",
      "18  2154 cells   807.399960  3.422030   170.935776   0.174411   0.962028  \n",
      "19  2154 cells   180.390998  2.590563   101.186690   0.493604   0.580813  \n",
      "Saved interactive visualization to 'analysis/noise_fits_interactive.html'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lmfit import Model\n",
    "import glob\n",
    "import re\n",
    "from bokeh.plotting import figure, output_file, save\n",
    "from bokeh.models import Select, ColumnDataSource, Div, CustomJS\n",
    "from bokeh.layouts import column, row\n",
    "\n",
    "BASE_URL = 'https://raw.githubusercontent.com/igor-sadalski/Scaling-up-measurement-noise-scaling-laws/main/'\n",
    "CALTECH_URL = 'https://raw.githubusercontent.com/ggdna/scScaling/main/results/'\n",
    "\n",
    "RENAME_DICT = {\n",
    "    'celltype.l3': 'Cell type MI',\n",
    "    'protein_counts': 'Protein MI',\n",
    "    'clone': 'Clonal MI',\n",
    "    'author_day': 'Temporal MI',\n",
    "    'ng_idx': 'Spatial MI',\n",
    "    'RandomProjection': 'Rand. Proj.'\n",
    "}\n",
    "\n",
    "# Load data\n",
    "gaussian_df = pd.read_csv(f'{CALTECH_URL}Caltech101_Gaussian.csv')\n",
    "gaussian_df['Scale'] = gaussian_df['Scale']**2\n",
    "res_df = pd.read_csv(f'{CALTECH_URL}Caltech101_resolution.csv')\n",
    "df = pd.read_csv(f'{BASE_URL}collect_mi_results.csv').replace(RENAME_DICT)\n",
    "sc_param_df_noise = pd.read_csv('analysis/final_results/scaling_plots_u_bar_138.109_I_max_1.419.csv').replace(RENAME_DICT)\n",
    "seq_df = pd.read_csv('seq/multisize_gisaid_results.csv')\n",
    "\n",
    "# Load TissueMNIST data\n",
    "csv_files = glob.glob('images/tissuemnist_models/result_*.csv')\n",
    "dfs_tissue = []\n",
    "for file in csv_files:\n",
    "    match = re.search(r'result_(.+)\\.csv', file)\n",
    "    if match.group(1) == 'clean':\n",
    "        downsampling_type, downsampling_level = 'clean', 0.0\n",
    "    elif 'pix' in match.group(1):\n",
    "        downsampling_type = 'pixel'\n",
    "        downsampling_level = float(match.group(1).split('_')[1][:-1])\n",
    "    elif 'gauss' in match.group(1):\n",
    "        downsampling_type = 'gaussian'\n",
    "        downsampling_level = float(match.group(1).split('_')[1][:-1])\n",
    "    else:\n",
    "        downsampling_type, downsampling_level = 'unknown', 0.0\n",
    "    df_temp = pd.read_csv(file)\n",
    "    df_temp['downsampling_level'] = downsampling_level\n",
    "    df_temp['downsampling_type'] = downsampling_type\n",
    "    dfs_tissue.append(df_temp)\n",
    "combined_df = pd.concat(dfs_tissue, ignore_index=True)\n",
    "\n",
    "# ============================================================================\n",
    "# Fitting Function\n",
    "# ============================================================================\n",
    "def info_scaling_model(x, A, B):\n",
    "    \"\"\"Parameterized info scaling: 0.5*log2((x*B+1)/(1+A*x))\"\"\"\n",
    "    return 0.5 * np.log2((x*B + 1)/(1 + A*x))\n",
    "\n",
    "def fit_info_model(x_data, y_data):\n",
    "    \"\"\"Fit info_scaling_model and return parameters, R², and result object if successful\"\"\"\n",
    "    model = Model(info_scaling_model)\n",
    "    params = model.make_params(A=1e-2, B=1e-2)\n",
    "    params['A'].min = params['B'].min = 0\n",
    "    \n",
    "    try:\n",
    "        result = model.fit(y_data, params, x=x_data)\n",
    "        a, b = result.params['A'], result.params['B']\n",
    "        if a.stderr and b.stderr and a.stderr < a.value and b.stderr < b.value:\n",
    "            u_bar = 1/a.value\n",
    "            I_max = 0.5*np.log2(b.value/a.value)\n",
    "            \n",
    "            # Calculate R²\n",
    "            ss_res = np.sum(result.residual**2)\n",
    "            ss_tot = np.sum((y_data - np.mean(y_data))**2)\n",
    "            r_squared = 1 - (ss_res / ss_tot)\n",
    "            \n",
    "            # Get confidence intervals (2-sigma)\n",
    "            u_bar_err = a.stderr / (a.value**2)  # Error propagation for 1/A\n",
    "            I_max_err = 0.5 / np.log(2) * np.sqrt((b.stderr/b.value)**2 + (a.stderr/a.value)**2)\n",
    "            \n",
    "            return u_bar, I_max, u_bar_err, I_max_err, r_squared, result\n",
    "    except:\n",
    "        pass\n",
    "    return None, None, None, None, None, None\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 1) Generate Table of Fitted Parameters\n",
    "# ============================================================================\n",
    "hue_order = ['Rand. Proj.', 'PCA', 'SCVI', 'Geneformer']\n",
    "hue_order_metrics = ['Protein MI', 'Clonal MI', 'Temporal MI', 'Spatial MI']\n",
    "\n",
    "# Storage for all curves\n",
    "all_curves = []\n",
    "\n",
    "# --- Single-cell noise curves ---\n",
    "for sig in hue_order_metrics:\n",
    "    for size in df['size'].unique():\n",
    "        for alg in hue_order:\n",
    "            data = df[(df['signal']==sig) & (df['size']==size) & (df['algorithm']==alg)]\n",
    "            if len(data) < 9:\n",
    "                continue\n",
    "            \n",
    "            x_data = data['umis_per_cell'].values\n",
    "            y_data = data['mi_value'].values\n",
    "            u_bar, I_max, u_bar_err, I_max_err, r_squared, result = fit_info_model(x_data, y_data)\n",
    "            \n",
    "            if u_bar is not None and I_max is not None:\n",
    "                # Generate confidence bands\n",
    "                x_fit = np.logspace(np.log10(x_data.min()/5), np.log10(x_data.max()*5), 200)\n",
    "                y_fit = result.eval(x=x_fit)\n",
    "                y_err = result.eval_uncertainty(x=x_fit, sigma=2)\n",
    "                \n",
    "                curve_id = f\"SC_{sig}_{alg}_size{int(size)}\"\n",
    "                all_curves.append({\n",
    "                    'curve_id': curve_id,\n",
    "                    'category': 'Single-cell',\n",
    "                    'metric': sig,\n",
    "                    'method': alg,\n",
    "                    'size': f\"{int(size)} cells\",\n",
    "                    'u_bar': u_bar,\n",
    "                    'I_max': I_max,\n",
    "                    'u_bar_err': u_bar_err,\n",
    "                    'I_max_err': I_max_err,\n",
    "                    'r_squared': r_squared,\n",
    "                    'x_data': x_data.tolist(),\n",
    "                    'y_data': y_data.tolist(),\n",
    "                    'x_fit': x_fit.tolist(),\n",
    "                    'y_fit': y_fit.tolist(),\n",
    "                    'y_err': y_err.tolist()\n",
    "                })\n",
    "\n",
    "# --- Caltech101 Gaussian ---\n",
    "for class_label in gaussian_df['Class label'].unique()[:-1]:\n",
    "    data = gaussian_df[gaussian_df['Class label'] == class_label]\n",
    "    x_data = 1/data['Scale'].values\n",
    "    y_data = data['MI'].values\n",
    "    \n",
    "    u_bar, I_max, u_bar_err, I_max_err, r_squared, result = fit_info_model(x_data, y_data)\n",
    "    if u_bar is not None and I_max is not None:\n",
    "        x_fit = np.logspace(np.log10(x_data.min()/5), np.log10(x_data.max()*5), 200)\n",
    "        y_fit = result.eval(x=x_fit)\n",
    "        y_err = result.eval_uncertainty(x=x_fit, sigma=2)\n",
    "        \n",
    "        curve_id = f\"Caltech101_Gaussian_class{class_label}\"\n",
    "        all_curves.append({\n",
    "            'curve_id': curve_id,\n",
    "            'category': 'Caltech101-Gaussian',\n",
    "            'metric': f'Class {class_label}',\n",
    "            'method': 'Mobilenet',\n",
    "            'size': 'N/A',\n",
    "            'u_bar': u_bar,\n",
    "            'I_max': I_max,\n",
    "            'u_bar_err': u_bar_err,\n",
    "            'I_max_err': I_max_err,\n",
    "            'r_squared': r_squared,\n",
    "            'x_data': x_data.tolist(),\n",
    "            'y_data': y_data.tolist(),\n",
    "            'x_fit': x_fit.tolist(),\n",
    "            'y_fit': y_fit.tolist(),\n",
    "            'y_err': y_err.tolist()\n",
    "        })\n",
    "\n",
    "# --- Caltech101 Resolution ---\n",
    "for class_label in res_df['Class label'].unique()[:-1]:\n",
    "    data = res_df[res_df['Class label'] == class_label]\n",
    "    x_data = 1/data['Factor'].values\n",
    "    y_data = data['MI'].values\n",
    "    \n",
    "    u_bar, I_max, u_bar_err, I_max_err, r_squared, result = fit_info_model(x_data, y_data)\n",
    "    if u_bar is not None and I_max is not None:\n",
    "        x_fit = np.logspace(np.log10(x_data.min()/5), np.log10(x_data.max()*5), 200)\n",
    "        y_fit = result.eval(x=x_fit)\n",
    "        y_err = result.eval_uncertainty(x=x_fit, sigma=2)\n",
    "        \n",
    "        curve_id = f\"Caltech101_Resolution_class{class_label}\"\n",
    "        all_curves.append({\n",
    "            'curve_id': curve_id,\n",
    "            'category': 'Caltech101-Pixelation',\n",
    "            'metric': f'Class {class_label}',\n",
    "            'method': 'Mobilenet',\n",
    "            'size': 'N/A',\n",
    "            'u_bar': u_bar,\n",
    "            'I_max': I_max,\n",
    "            'u_bar_err': u_bar_err,\n",
    "            'I_max_err': I_max_err,\n",
    "            'r_squared': r_squared,\n",
    "            'x_data': x_data.tolist(),\n",
    "            'y_data': y_data.tolist(),\n",
    "            'x_fit': x_fit.tolist(),\n",
    "            'y_fit': y_fit.tolist(),\n",
    "            'y_err': y_err.tolist()\n",
    "        })\n",
    "\n",
    "# --- Sequences (ESM2 models) ---\n",
    "model_sizes = sorted(seq_df['model_size'].unique())\n",
    "for model_size in model_sizes:\n",
    "    data = seq_df[seq_df['model_size'] == model_size]\n",
    "    x_data = data['true/error'].values\n",
    "    y_data = data['mutual_information'].values\n",
    "    \n",
    "    u_bar, I_max, u_bar_err, I_max_err, r_squared, result = fit_info_model(x_data, y_data)\n",
    "    if u_bar is not None and I_max is not None:\n",
    "        x_fit = np.logspace(np.log10(x_data.min()/5), np.log10(x_data.max()*5), 200)\n",
    "        y_fit = result.eval(x=x_fit)\n",
    "        y_err = result.eval_uncertainty(x=x_fit, sigma=2)\n",
    "        \n",
    "        curve_id = f\"Sequences_ESM2_{model_size}\"\n",
    "        all_curves.append({\n",
    "            'curve_id': curve_id,\n",
    "            'category': 'Sequences',\n",
    "            'metric': 'Collection month MI',\n",
    "            'method': f'ESM2-{model_size}',\n",
    "            'size': 'N/A',\n",
    "            'u_bar': u_bar,\n",
    "            'I_max': I_max,\n",
    "            'u_bar_err': u_bar_err,\n",
    "            'I_max_err': I_max_err,\n",
    "            'r_squared': r_squared,\n",
    "            'x_data': x_data.tolist(),\n",
    "            'y_data': y_data.tolist(),\n",
    "            'x_fit': x_fit.tolist(),\n",
    "            'y_fit': y_fit.tolist(),\n",
    "            'y_err': y_err.tolist()\n",
    "        })\n",
    "\n",
    "# --- TissueMNIST Pixel Downsampling ---\n",
    "label_map = {\n",
    "    'ova_mi_continuous_Class_0': 'Collecting Duct',\n",
    "    'ova_mi_continuous_Class_1': 'Distal Convoluted Tubule',\n",
    "    'ova_mi_continuous_Class_2': 'Glomerular endothelial',\n",
    "    'ova_mi_continuous_Class_3': 'Interstitial endothelial',\n",
    "    'ova_mi_continuous_Class_4': 'Leukocytes',\n",
    "    'ova_mi_continuous_Class_5': 'Podocytes',\n",
    "    'ova_mi_continuous_Class_6': 'Proximal Tubule',\n",
    "    'ova_mi_continuous_Class_7': 'Thick Ascending Limb',\n",
    "    'mi_score': '8-class MI',\n",
    "}\n",
    "\n",
    "pix = combined_df[combined_df['downsampling_type'] == 'pixel'].copy()\n",
    "pix['inv_factor'] = 1 / pix['downsampling_level']\n",
    "ova_columns = ['mi_score'] + [col for col in pix.columns if 'ova_mi_continuous' in col]\n",
    "\n",
    "for col in ova_columns:\n",
    "    mask = ~pix[col].isna() & ~pix['inv_factor'].isna()\n",
    "    x_data = (pix[mask]['inv_factor'].values)**2\n",
    "    y_data = pix[mask][col].values\n",
    "    \n",
    "    if len(x_data) < 3:\n",
    "        continue\n",
    "    \n",
    "    u_bar, I_max, u_bar_err, I_max_err, r_squared, result = fit_info_model(x_data, y_data)\n",
    "    if u_bar is not None and I_max is not None:\n",
    "        x_fit = np.logspace(np.log10(x_data.min()/5), np.log10(x_data.max()*5), 200)\n",
    "        y_fit = result.eval(x=x_fit)\n",
    "        y_err = result.eval_uncertainty(x=x_fit, sigma=2)\n",
    "        \n",
    "        metric_name = label_map.get(col, col)\n",
    "        curve_id = f\"TissueMNIST_Pixel_{col}\"\n",
    "        all_curves.append({\n",
    "            'curve_id': curve_id,\n",
    "            'category': 'TissueMNIST-Pixelation',\n",
    "            'metric': metric_name,\n",
    "            'method': 'Mobilenet',\n",
    "            'size': 'N/A',\n",
    "            'u_bar': u_bar,\n",
    "            'I_max': I_max,\n",
    "            'u_bar_err': u_bar_err,\n",
    "            'I_max_err': I_max_err,\n",
    "            'r_squared': r_squared,\n",
    "            'x_data': x_data.tolist(),\n",
    "            'y_data': y_data.tolist(),\n",
    "            'x_fit': x_fit.tolist(),\n",
    "            'y_fit': y_fit.tolist(),\n",
    "            'y_err': y_err.tolist()\n",
    "        })\n",
    "\n",
    "# --- TissueMNIST Gaussian Noise ---\n",
    "gauss = combined_df[combined_df['downsampling_type'] == 'gaussian'].copy()\n",
    "\n",
    "for col in ova_columns:\n",
    "    mask = ~gauss[col].isna()\n",
    "    if mask.sum() < 3:\n",
    "        continue\n",
    "    x_data = 1/gauss[mask]['downsampling_level'].values\n",
    "    y_data = gauss[mask][col].values\n",
    "    \n",
    "    u_bar, I_max, u_bar_err, I_max_err, r_squared, result = fit_info_model(x_data, y_data)\n",
    "    if u_bar is not None and I_max is not None:\n",
    "        x_fit = np.logspace(np.log10(x_data.min()/5), np.log10(x_data.max()*5), 200)\n",
    "        y_fit = result.eval(x=x_fit)\n",
    "        y_err = result.eval_uncertainty(x=x_fit, sigma=2)\n",
    "        \n",
    "        metric_name = label_map.get(col, col)\n",
    "        curve_id = f\"TissueMNIST_Gaussian_{col}\"\n",
    "        all_curves.append({\n",
    "            'curve_id': curve_id,\n",
    "            'category': 'TissueMNIST-Gaussian',\n",
    "            'metric': metric_name,\n",
    "            'method': 'Mobilenet',\n",
    "            'size': 'N/A',\n",
    "            'u_bar': u_bar,\n",
    "            'I_max': I_max,\n",
    "            'u_bar_err': u_bar_err,\n",
    "            'I_max_err': I_max_err,\n",
    "            'r_squared': r_squared,\n",
    "            'x_data': x_data.tolist(),\n",
    "            'y_data': y_data.tolist(),\n",
    "            'x_fit': x_fit.tolist(),\n",
    "            'y_fit': y_fit.tolist(),\n",
    "            'y_err': y_err.tolist()\n",
    "        })\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "params_df = pd.DataFrame([{\n",
    "    'curve_id': c['curve_id'],\n",
    "    'category': c['category'],\n",
    "    'metric': c['metric'],\n",
    "    'method': c['method'],\n",
    "    'size': c['size'],\n",
    "    'u_bar': c['u_bar'],\n",
    "    'I_max': c['I_max'],\n",
    "    'u_bar_err': c['u_bar_err'],\n",
    "    'I_max_err': c['I_max_err'],\n",
    "    'r_squared': c['r_squared']\n",
    "} for c in all_curves])\n",
    "\n",
    "params_df.to_csv('analysis/noise_fit_parameters.csv', index=False)\n",
    "print(f\"Saved {len(params_df)} curves to 'analysis/noise_fit_parameters.csv'\")\n",
    "print(params_df.head(20))\n",
    "\n",
    "# ============================================================================\n",
    "# 2) Bokeh Interactive Visualization with Responsive Dropdowns\n",
    "# ============================================================================\n",
    "\n",
    "# Get unique values for initial category\n",
    "categories = sorted(list(set(c['category'] for c in all_curves)))\n",
    "\n",
    "# Create initial data source with first curve\n",
    "first_curve = all_curves[0]\n",
    "\n",
    "# Get valid options for first category\n",
    "first_cat_curves = [c for c in all_curves if c['category'] == first_curve['category']]\n",
    "initial_metrics = sorted(list(set(c['metric'] for c in first_cat_curves)))\n",
    "\n",
    "first_metric_curves = [c for c in first_cat_curves if c['metric'] == first_curve['metric']]\n",
    "initial_methods = sorted(list(set(c['method'] for c in first_metric_curves)))\n",
    "\n",
    "first_method_curves = [c for c in first_metric_curves if c['method'] == first_curve['method']]\n",
    "initial_sizes = sorted(list(set(c['size'] for c in first_method_curves)))\n",
    "\n",
    "x_data = np.array(first_curve['x_data'])\n",
    "y_data = np.array(first_curve['y_data'])\n",
    "sort_idx = np.argsort(x_data)\n",
    "x_sorted = x_data[sort_idx]\n",
    "y_sorted = y_data[sort_idx]\n",
    "\n",
    "x_fit = np.array(first_curve['x_fit'])\n",
    "y_fit = np.array(first_curve['y_fit'])\n",
    "y_err = np.array(first_curve['y_err'])\n",
    "\n",
    "source_scatter = ColumnDataSource(data=dict(x=x_sorted, y=y_sorted))\n",
    "source_fit = ColumnDataSource(data=dict(x=x_fit, y=y_fit))\n",
    "source_ci_upper = ColumnDataSource(data=dict(x=x_fit, y=y_fit+y_err))\n",
    "source_ci_lower = ColumnDataSource(data=dict(x=x_fit, y=y_fit-y_err))\n",
    "\n",
    "# Create figure\n",
    "p = figure(title=f\"{first_curve['category']} | {first_curve['metric']} | {first_curve['method']} | {first_curve['size']}\", \n",
    "           x_axis_type=\"log\", width=600, height=400,\n",
    "           x_axis_label=r\"$\\eta$\", y_axis_label=\"auxiliary MI (bits)\")\n",
    "\n",
    "p.xaxis.axis_label_text_font_size = \"14pt\"\n",
    "p.yaxis.axis_label_text_font_size = \"14pt\"\n",
    "p.xaxis.major_label_text_font_size = \"12pt\"\n",
    "p.yaxis.major_label_text_font_size = \"12pt\"\n",
    "\n",
    "# Create combined source for confidence band\n",
    "source_ci = ColumnDataSource(data=dict(x=x_fit, y1=y_fit-y_err, y2=y_fit+y_err))\n",
    "\n",
    "# Then in the plot:\n",
    "p.varea(x='x', y1='y1', y2='y2', source=source_ci, \n",
    "        alpha=0.2, color='lightblue', legend_label=\"2 sigma CI\")\n",
    "\n",
    "p.scatter('x', 'y', source=source_scatter, size=10, color='purple', alpha=0.7, legend_label=\"data\")\n",
    "p.line('x', 'y', source=source_fit, line_width=2, color='lightblue', line_dash='dashed', legend_label=\"fit\")\n",
    "p.legend.location = \"bottom_right\"\n",
    "\n",
    "# Create parameter display\n",
    "u_bar = first_curve['u_bar']\n",
    "I_max = first_curve['I_max']\n",
    "u_bar_err = first_curve['u_bar_err']\n",
    "I_max_err = first_curve['I_max_err']\n",
    "r_squared = first_curve['r_squared']\n",
    "\n",
    "param_div = Div(text=f\"\"\"\n",
    "<div style=\"font-size: 16px; padding: 10px; background-color: #f0f0f0; border-radius: 5px;\">\n",
    "    <b>Fitted Parameters:</b><br>\n",
    "    <span style=\"color: darkgreen;\">ū = {u_bar:.4f} ± {u_bar_err:.4f}</span><br>\n",
    "    <span style=\"color: darkblue;\">I<sub>max</sub> = {I_max:.4f} ± {I_max_err:.4f} bits</span><br>\n",
    "    <span style=\"color: purple;\">R² = {r_squared:.4f}</span><br>\n",
    "</div>\n",
    "\"\"\", width=300)\n",
    "\n",
    "# Create dropdown menus with initial valid options\n",
    "select_category = Select(title=\"data domain:\", value=first_curve['category'], options=categories, width=200)\n",
    "select_metric = Select(title=\"metric:\", value=first_curve['metric'], options=initial_metrics, width=200)\n",
    "select_method = Select(title=\"method:\", value=first_curve['method'], options=initial_methods, width=200)\n",
    "select_size = Select(title=\"dataset size:\", value=first_curve['size'], options=initial_sizes, width=200)\n",
    "\n",
    "# Prepare all curve data as JSON for JavaScript callback\n",
    "import json\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.integer, np.int64)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.floating, np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super().default(obj)\n",
    "\n",
    "curve_data_json = json.dumps([{\n",
    "    'category': c['category'],\n",
    "    'metric': c['metric'],\n",
    "    'method': c['method'],\n",
    "    'size': c['size'],\n",
    "    'x': c['x_data'],\n",
    "    'y': c['y_data'],\n",
    "    'x_fit': c['x_fit'],\n",
    "    'y_fit': c['y_fit'],\n",
    "    'y_err': c['y_err'],\n",
    "    'u_bar': c['u_bar'],\n",
    "    'I_max': c['I_max'],\n",
    "    'u_bar_err': c['u_bar_err'],\n",
    "    'I_max_err': c['I_max_err'],\n",
    "    'r_squared': c['r_squared']\n",
    "} for c in all_curves], cls=NumpyEncoder)\n",
    "\n",
    "# JavaScript callback for dropdowns\n",
    "callback = CustomJS(args=dict(\n",
    "    source_scatter=source_scatter, \n",
    "    source_fit=source_fit,\n",
    "    source_ci=source_ci,\n",
    "    param_div=param_div,\n",
    "    p=p,\n",
    "    select_category=select_category,\n",
    "    select_metric=select_metric,\n",
    "    select_method=select_method,\n",
    "    select_size=select_size\n",
    "), code=f\"\"\"\n",
    "    const all_curves = {curve_data_json};\n",
    "    \n",
    "    // Determine which dropdown triggered the callback\n",
    "    const trigger = cb_obj;\n",
    "    \n",
    "    // Get current selections\n",
    "    let sel_cat = select_category.value;\n",
    "    let sel_met = select_metric.value;\n",
    "    let sel_meth = select_method.value;\n",
    "    let sel_size = select_size.value;\n",
    "    \n",
    "    // Update available options based on selections\n",
    "    // Start from the triggered dropdown and cascade down\n",
    "    \n",
    "    // Filter by category\n",
    "    const cat_curves = all_curves.filter(c => c.category === sel_cat);\n",
    "    const avail_metrics = [...new Set(cat_curves.map(c => c.metric))].sort().reverse();\n",
    "    \n",
    "    // If metric is no longer valid, select first available\n",
    "    if (!avail_metrics.includes(sel_met)) {{\n",
    "        sel_met = avail_metrics[0];\n",
    "        select_metric.value = sel_met;\n",
    "    }}\n",
    "    select_metric.options = avail_metrics;\n",
    "    \n",
    "    // Filter by category and metric\n",
    "    const met_curves = cat_curves.filter(c => c.metric === sel_met);\n",
    "    const avail_methods = [...new Set(met_curves.map(c => c.method))].sort().reverse();\n",
    "    \n",
    "    // If method is no longer valid, select first available\n",
    "    if (!avail_methods.includes(sel_meth)) {{\n",
    "        sel_meth = avail_methods[0];\n",
    "        select_method.value = sel_meth;\n",
    "    }}\n",
    "    select_method.options = avail_methods;\n",
    "    \n",
    "    // Filter by category, metric, and method\n",
    "    const meth_curves = met_curves.filter(c => c.method === sel_meth);\n",
    "    const avail_sizes = [...new Set(meth_curves.map(c => c.size))].sort().reverse();\n",
    "    \n",
    "    // If size is no longer valid, select first available\n",
    "    if (!avail_sizes.includes(sel_size)) {{\n",
    "        sel_size = avail_sizes[0];\n",
    "        select_size.value = sel_size;\n",
    "    }}\n",
    "    select_size.options = avail_sizes;\n",
    "    \n",
    "    // Find matching curve with final selections\n",
    "    const curve = all_curves.find(c => \n",
    "        c.category === sel_cat && \n",
    "        c.metric === sel_met && \n",
    "        c.method === sel_meth && \n",
    "        c.size === sel_size\n",
    "    );\n",
    "    \n",
    "    if (!curve) {{\n",
    "        console.log(\"No matching curve found\");\n",
    "        return;\n",
    "    }}\n",
    "    \n",
    "    // Update scatter data\n",
    "    const x = curve.x;\n",
    "    const y = curve.y;\n",
    "    \n",
    "    // Sort by x\n",
    "    const indices = [...x.keys()].sort((a, b) => x[a] - x[b]);\n",
    "    const x_sorted = indices.map(i => x[i]);\n",
    "    const y_sorted = indices.map(i => y[i]);\n",
    "    \n",
    "    source_scatter.data = {{x: x_sorted, y: y_sorted}};\n",
    "    \n",
    "    // Update fit line and confidence bands\n",
    "    source_fit.data = {{x: curve.x_fit, y: curve.y_fit}};\n",
    "    \n",
    "    const y_upper = curve.y_fit.map((val, i) => val + curve.y_err[i]);\n",
    "    const y_lower = curve.y_fit.map((val, i) => val - curve.y_err[i]);\n",
    "\n",
    "    source_ci.data = {{x: curve.x_fit, y1: y_lower, y2: y_upper}};\n",
    "    \n",
    "    // Update title\n",
    "    p.title.text = sel_cat + \" | \" + sel_met + \" | \" + sel_meth + \" | \" + sel_size;\n",
    "    \n",
    "    // Update parameter display\n",
    "    param_div.text = `\n",
    "    <div style=\"font-size: 16px; padding: 10px; background-color: #f0f0f0; border-radius: 5px;\">\n",
    "        <b>Fitted Parameters:</b><br>\n",
    "        <span style=\"color: darkgreen;\">ū = ${{curve.u_bar.toFixed(4)}} ± ${{curve.u_bar_err.toFixed(4)}}</span><br>\n",
    "        <span style=\"color: darkblue;\">I<sub>max</sub> = ${{curve.I_max.toFixed(4)}} ± ${{curve.I_max_err.toFixed(4)}} bits</span><br>\n",
    "        <span style=\"color: purple;\">R² = ${{curve.r_squared.toFixed(4)}}</span><br>\n",
    "    </div>\n",
    "    `;\n",
    "\"\"\")\n",
    "\n",
    "select_category.js_on_change('value', callback)\n",
    "select_metric.js_on_change('value', callback)\n",
    "select_method.js_on_change('value', callback)\n",
    "select_size.js_on_change('value', callback)\n",
    "\n",
    "# Layout\n",
    "dropdowns = row(select_category, select_metric, select_method, select_size)\n",
    "layout = column(dropdowns, row(p, param_div))\n",
    "\n",
    "# Save to HTML\n",
    "output_file(\"analysis/noise_fits_interactive.html\", title=\"Noise scaling zoo\")\n",
    "save(layout)\n",
    "print(\"Saved interactive visualization to 'analysis/noise_fits_interactive.html'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782cc59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
